{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this short \"draft\" I'll use GAN implementation from https://habrahabr.ru/post/332000/ on :\n",
    "- MNIST - this'll be samples from \"normal\" distribution\n",
    "- normal random noise - this'll be samples from other distribution\n",
    "\n",
    "So I'll try to predict - are image comes from \"normal\" or \"anomaly\" distribution by output of dicriminator network (of GAN that's trained on MNIST without anomaly samples).\n",
    "\n",
    "# GAN implementation/train\n",
    "Firstly let's initialize imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.layers import Dropout, BatchNormalization, Reshape, Flatten, RepeatVector\n",
    "from keras.layers import Lambda, Dense, Input, Conv2D, MaxPool2D, UpSampling2D, concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test  = x_test .astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test  = np.reshape(x_test,  (len(x_test),  28, 28, 1))\n",
    "\n",
    "y_train_cat = to_categorical(y_train).astype(np.float32)\n",
    "y_test_cat  = to_categorical(y_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "batch_shape = (batch_size, 28, 28, 1)\n",
    "latent_dim = 2\n",
    "num_classes = 10\n",
    "dropout_rate = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch(x, y):\n",
    "    n_batches = x.shape[0] // batch_size\n",
    "    while(True):\n",
    "        for i in range(n_batches):\n",
    "            yield x[batch_size*i: batch_size*(i+1)], y[batch_size*i: batch_size*(i+1)]\n",
    "        idxs = np.random.permutation(y.shape[0])\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "\n",
    "\n",
    "train_batches_it = gen_batch(x_train, y_train_cat)\n",
    "test_batches_it  = gen_batch(x_test,  y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = tf.placeholder(tf.float32, shape=(None, 28, 28, 1),   name='image')\n",
    "z_ = tf.placeholder(tf.float32, shape=(None, latent_dim),  name='z')\n",
    "\n",
    "img = Input(tensor=x_)\n",
    "z   = Input(tensor=z_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('generator'):\n",
    "    x = z\n",
    "    x = Dense(7*7*64, activation='relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Reshape((7, 7, 64))(x)\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(5, 5), activation='relu', padding='same')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "\n",
    "    generated = Conv2D(1, kernel_size=(5, 5), activation='sigmoid', padding='same')(x)\n",
    "generator = Model(z, generated, name='generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('discrim'):\n",
    "    x = Conv2D(128, kernel_size=(7, 7), strides=(2, 2), padding='same')(img)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = MaxPool2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    l = Conv2D(128, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = LeakyReLU()(l)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    h = Flatten()(x)\n",
    "    d = Dense(1, activation='sigmoid')(h)\n",
    "discrim = Model(img, d, name='Discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_z = generator(z)\n",
    "\n",
    "discr_img   = discrim(img)\n",
    "discr_gen_z = discrim(generated_z)\n",
    "\n",
    "gan_model = Model(z, discr_gen_z, name='GAN')\n",
    "gan   = gan_model(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dis_img   = tf.reduce_mean(-tf.log(discr_img + 1e-10))\n",
    "log_dis_gen_z = tf.reduce_mean(-tf.log(1. - discr_gen_z + 1e-10))\n",
    "\n",
    "L_gen = -log_dis_gen_z\n",
    "L_dis = 0.5*(log_dis_gen_z + log_dis_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_gen = tf.train.RMSPropOptimizer(0.0003)\n",
    "optimizer_dis = tf.train.RMSPropOptimizer(0.0001)\n",
    "\n",
    "# Переменные генератора и дискриминаторы (отдельно) для оптимизаторов\n",
    "generator_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"generator\")\n",
    "discrim_vars   = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"discrim\")\n",
    "\n",
    "step_gen = optimizer_gen.minimize(L_gen, var_list=generator_vars)\n",
    "step_dis = optimizer_dis.minimize(L_dis, var_list=discrim_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг обучения генератора\n",
    "def step(image, zp):\n",
    "    l_dis, _ = sess.run([L_dis, step_gen], feed_dict={z:zp, img:image, K.learning_phase():1})\n",
    "    return l_dis\n",
    "\n",
    "# Шаг обучения дискриминатора\n",
    "def step_d(image, zp):\n",
    "    l_dis, _ = sess.run([L_dis, step_dis], feed_dict={z:zp, img:image, K.learning_phase():1})\n",
    "    return l_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_per_period = 20 # Как часто сохранять картинки\n",
    "k_step = 5 # Количество шагов, которые могут делать дискриминатор и генератор во внутреннем цикле\n",
    "\n",
    "for i in range(5000):\n",
    "    # Достанем новый батч\n",
    "    b0, b1 = next(train_batches_it)\n",
    "    zp = np.random.randn(batch_size, latent_dim)\n",
    "    # Шаги обучения дискриминатора\n",
    "    for j in range(k_step):\n",
    "        l_d = step_d(b0, zp)\n",
    "        b0, b1 = next(train_batches_it)\n",
    "        zp = np.random.randn(batch_size, latent_dim)\n",
    "        if l_d < 1.0:\n",
    "            break\n",
    "\n",
    "    # Шаги обучения генератора\n",
    "    for j in range(k_step):\n",
    "        l_d = step(b0, zp)\n",
    "        if l_d > 0.4:\n",
    "            break\n",
    "        b0, b1 = next(train_batches_it)\n",
    "        zp = np.random.randn(batch_size, latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "Now I'll make next things:\n",
    "- build discriminator prediction for test part of MNIST\n",
    "- generate random noise \"images\" - and build discriminator prediction for noise\n",
    "- see histograms of discriminator output for test set / noise\n",
    "- concatenate both predictions and check F1 score, where:\n",
    "    - true values - 1.0 for noise samples, 0.0 for test set samples\n",
    "    - predicted values:\n",
    "        - 1.0 if abs(D(sample) - 0.5) > 0.2, where 0.5/0.2 - some thresholds - which'll be hyperperemeters of algorythm. I used 0.5 - because seems like it'll be \"optimal\" output for discriminator that's unable to differentiate - are sample goes from MNIST or from generator.\n",
    "        - else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "i = 0\n",
    "for X, _ in gen_batch(x_test,  y_test_cat):\n",
    "    test_predictions += sess.run(discr_img, {img: X, K.learning_phase():0}).ravel().tolist()\n",
    "    i += 1\n",
    "    if i == 39:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 28, 28, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = np.random.randn(256, 28, 28, 1)\n",
    "noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_prediction = sess.run(discr_img, {img: noise, K.learning_phase():0}).ravel().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = np.array(test_predictions)\n",
    "noise_prediction = np.array(noise_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEPFJREFUeJzt3X+s3Xddx/Hniw6mDIQtu9TSH7bEIraEDbxWFGKQBddk\nYEtcZjFKg0sazURMjNqR+CukSfmHQMRhGkCaCNQGmKuA4Cwg0Sijw8LWbsvq1rHWbh1MxBEzbHn7\nx/0ODqW395x7z7nn3E+fj6Q53/M5n+8970+/3et+9vl+z/ekqpAktetp4y5AkjRaBr0kNc6gl6TG\nGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcZeMuwCAK6+8stauXTvuMiRpSbnzzju/VlVTc/Wb\niKBfu3Ythw4dGncZkrSkJHmon34u3UhS4wx6SWqcQS9JjTPoJalxfQV9kucm+UiSe5Pck+Rnk1yR\n5PYk93ePl/f0vznJsST3Jbl2dOVLkubS74z+XcCnqupFwFXAPcBO4GBVrQcOds9JsgHYBmwENgO3\nJFk27MIlSf2ZM+iTPAf4eeB9AFX17ar6BrAF2Nt12wts7ba3APuq6smqehA4BmwaduGSpP70M6Nf\nBzwG/FWSf0/y3iSXAcur6lTX5xFgebe9Eni4Z/8TXdv3SbIjyaEkhx577LH5j0CSdEH9BP0lwMuA\n91TVS4Fv0S3TPKVmvnh2oC+frao9VTVdVdNTU3N+sEuSNE/9fDL2BHCiqr7QPf8IM0H/aJIVVXUq\nyQrgdPf6SWB1z/6rujZpSVq78xPnbT+++7pFrkSanzln9FX1CPBwkp/omq4BjgIHgO1d23bgtm77\nALAtyaVJ1gHrgTuGWrUkqW/93uvmzcAHkzwDeAB4EzO/JPYnuRF4CLgBoKqOJNnPzC+DM8BNVXV2\n6JVLkvrSV9BX1WFg+jwvXTNL/13ArgXUJU08l3S0VPjJWElqnEEvSY0z6CWpcQa9JDXOoJekxhn0\nktS4ifjOWGkSzHa55LB+jpddalyc0UtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGeXmlLjrDuoxS\nWiqc0UtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnLdAUJMm8TYH\ng9bkN1JpWPqa0Sc5nuSuJIeTHOrarkhye5L7u8fLe/rfnORYkvuSXDuq4iVJcxtk6eYXqurqqpru\nnu8EDlbVeuBg95wkG4BtwEZgM3BLkmVDrFmSNICFrNFvAfZ223uBrT3t+6rqyap6EDgGbFrA+0iS\nFqDfoC/gH5PcmWRH17a8qk51248Ay7vtlcDDPfue6NokSWPQ78nYV1bVySTPA25Pcm/vi1VVSWqQ\nN+5+YewAWLNmzSC7SpIG0NeMvqpOdo+ngVuZWYp5NMkKgO7xdNf9JLC6Z/dVXdu5P3NPVU1X1fTU\n1NT8RyBJuqA5gz7JZUme/dQ28IvA3cABYHvXbTtwW7d9ANiW5NIk64D1wB3DLlyS1J9+lm6WA7cm\near/h6rqU0m+COxPciPwEHADQFUdSbIfOAqcAW6qqrMjqV6SNKc5g76qHgCuOk/714FrZtlnF7Br\nwdVJkhbMWyBIUuO8BYKWhEm8pYG0VDijl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9\nJDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapx3r5Qm1Gx37Dy++7pFrkRLnTN6SWqcQS9JjTPoJalx\nBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnJ+M1VjM9qlPScPXd9AnWQYcAk5W1WuTXAH8DbAW\nOA7cUFX/1fW9GbgROAv8TlV9esh1Sxctb42gQQ2ydPMW4J6e5zuBg1W1HjjYPSfJBmAbsBHYDNzS\n/ZKQJI1BX0GfZBVwHfDenuYtwN5uey+wtad9X1U9WVUPAseATcMpV5I0qH5n9O8E/gD4Tk/b8qo6\n1W0/AizvtlcCD/f0O9G1SZLGYM6gT/Ja4HRV3Tlbn6oqoAZ54yQ7khxKcuixxx4bZFdJ0gD6mdG/\nAvilJMeBfcCrk/w18GiSFQDd4+mu/0lgdc/+q7q271NVe6pquqqmp6amFjAESdKFzBn0VXVzVa2q\nqrXMnGT9TFX9GnAA2N512w7c1m0fALYluTTJOmA9cMfQK5ck9WUh19HvBvYnuRF4CLgBoKqOJNkP\nHAXOADdV1dkFVypJmpeBgr6qPgd8rtv+OnDNLP12AbsWWJskaQi8BYIkNc6gl6TGGfSS1DiDXpIa\nZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEG\nvSQ1biFfJShpgqzd+Ynzth/ffd0iV6JJ44xekhpn0EtS4wx6SWqcQS9JjfNkrEZqthOEkhaPM3pJ\napxBL0mNc+lGatyFls+8xv7iMOeMPskPJbkjyZeTHEnyZ137FUluT3J/93h5zz43JzmW5L4k145y\nAJKkC+tn6eZJ4NVVdRVwNbA5ycuBncDBqloPHOyek2QDsA3YCGwGbkmybBTFS5LmNmfQ14wnuqdP\n7/4UsAXY27XvBbZ221uAfVX1ZFU9CBwDNg21aklS3/o6GZtkWZLDwGng9qr6ArC8qk51XR4Blnfb\nK4GHe3Y/0bVJksagr5OxVXUWuDrJc4Fbk7z4nNcrSQ3yxkl2ADsA1qxZM8iumkBeLy9NroEur6yq\nbwCfZWbt/dEkKwC6x9Ndt5PA6p7dVnVt5/6sPVU1XVXTU1NT86ldktSHfq66mepm8iT5YeA1wL3A\nAWB71207cFu3fQDYluTSJOuA9cAdwy5cktSffpZuVgB7uytnngbsr6qPJ/lXYH+SG4GHgBsAqupI\nkv3AUeAMcFO39CNJGoM5g76qvgK89DztXweumWWfXcCuBVcnSVowb4EgSY0z6CWpcQa9JDXOoJek\nxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4/r6zlhJ\nbZrtu36P775ukSvRKDmjl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0\nktS4OYM+yeokn01yNMmRJG/p2q9IcnuS+7vHy3v2uTnJsST3Jbl2lAOQJF1YPzP6M8DvVdUG4OXA\nTUk2ADuBg1W1HjjYPad7bRuwEdgM3JJk2SiKlyTNbc6gr6pTVfWlbvt/gHuAlcAWYG/XbS+wtdve\nAuyrqier6kHgGLBp2IVLkvoz0N0rk6wFXgp8AVheVae6lx4BlnfbK4F/69ntRNd27s/aAewAWLNm\nzSBlaIxmu9uhpMnV98nYJM8CPgr8blV9s/e1qiqgBnnjqtpTVdNVNT01NTXIrpKkAfQV9EmezkzI\nf7CqPtY1P5pkRff6CuB0134SWN2z+6quTZI0Bv1cdRPgfcA9VfWOnpcOANu77e3AbT3t25JcmmQd\nsB64Y3glS5IG0c8a/SuAXwfuSnK4a3srsBvYn+RG4CHgBoCqOpJkP3CUmSt2bqqqs0OvXJLUlzmD\nvqr+GcgsL18zyz67gF0LqEuSNCR+Z6ykH+B3ybbFWyBIUuMMeklqnEEvSY0z6CWpcQa9JDXOoJek\nxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mN8143Oi+/SUpqhzN6SWqcQS9JjTPoJalxrtFL6pv3qV+a\nnNFLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGjdn0Cd5f5LTSe7uabsiye1J7u8e\nL+957eYkx5Lcl+TaURUuSepPPzP6DwCbz2nbCRysqvXAwe45STYA24CN3T63JFk2tGolSQObM+ir\n6vPA4+c0bwH2dtt7ga097fuq6smqehA4BmwaUq2SpHmY7xr98qo61W0/AizvtlcCD/f0O9G1SZLG\nZME3NauqSlKD7pdkB7ADYM2aNQstQ/PkF4xI7ZvvjP7RJCsAusfTXftJYHVPv1Vd2w+oqj1VNV1V\n01NTU/MsQ5I0l/nO6A8A24Hd3eNtPe0fSvIO4PnAeuCOhRYpabJ5++LJNmfQJ/kw8CrgyiQngD9h\nJuD3J7kReAi4AaCqjiTZDxwFzgA3VdXZEdUuSerDnEFfVW+Y5aVrZum/C9i1kKIkScPjJ2MlqXF+\nleBFwqtrpIuXM3pJapxBL0mNc+lG0sh42eVkcEYvSY0z6CWpcS7dSFp0LuksLoO+MV5GKelcLt1I\nUuMMeklqnEEvSY0z6CWpcZ6MXYI84SppEM7oJalxBr0kNc6lG0kTww9SjYYzeklqnEEvSY1z6UbS\nxHNJZ2EM+gnmZZSShsGlG0lqnEEvSY1z6UZSc1zT/37O6CWpcc7oJS1Zg16wcLHO9EcW9Ek2A+8C\nlgHvrardo3qvSePVMpImyUiCPsky4C+A1wAngC8mOVBVR0fxfpK0EPOZnC2l/wsY1Yx+E3Csqh4A\nSLIP2AJMdNAPerCX0oGWNFxLaRloVEG/Eni45/kJ4GdG9F4D/4UPa2nFJRpJ55rECePYTsYm2QHs\n6J4+keS+AX/ElcDXLvgeb59PZRNrzvE2xLG262Iab19jXWBO/Vg/nUYV9CeB1T3PV3Vt31VVe4A9\n832DJIeqanq++y81F9N4HWu7LqbxTtJYR3Ud/ReB9UnWJXkGsA04MKL3kiRdwEhm9FV1JslvA59m\n5vLK91fVkVG8lyTpwka2Rl9VnwQ+OaqfzwKWfZaoi2m8jrVdF9N4J2asqapx1yBJGiHvdSNJjZv4\noE+yOcl9SY4l2Xme17ck+UqSw0kOJXnlOOochrnG2tPvp5OcSXL9YtY3bH0c21cl+e/u2B5O8sfj\nqHMY+jm23XgPJzmS5J8Wu8Zh6eO4/n7PMb07ydkkV4yj1mHoY7zPSfJ3Sb7cHds3LXqRVTWxf5g5\nkfsfwAuAZwBfBjac0+dZfG8J6iXAveOue1Rj7en3GWbOf1w/7rpHfGxfBXx83LUu0lify8wnx9d0\nz5837rpHNdZz+r8O+My46x7xsX0r8PZuewp4HHjGYtY56TP6795Koaq+DTx1K4XvqqonqvsbBC4D\nlupJhznH2nkz8FHg9GIWNwL9jrcF/Yz1V4GPVdVXAapqqR7fQY/rG4APL0plo9HPeAt4dpIwMzF9\nHDizmEVOetCf71YKK8/tlOT1Se4FPgH8xiLVNmxzjjXJSuD1wHsWsa5R6evYAj/XLc39fZKNi1Pa\n0PUz1hcClyf5XJI7k7xx0aobrn6PK0meCWxmZuKyVPUz3ncDPwn8J3AX8Jaq+s7ilDdj0oO+L1V1\na1W9CNgKvG3c9YzQO4E/XOx/JGP0JWaWMl4C/Dnwt2OuZ5QuAX4KuA64FvijJC8cb0kj9zrgX6rq\n8XEXMmLXAoeB5wNXA+9O8iOLWcCkB/2ct1LoVVWfB16Q5MpRFzYC/Yx1GtiX5DhwPXBLkq2LU97Q\n9XObjG9W1RPd9ieBpzd8bE8An66qb1XV14DPA1ctUn3DNMh/s9tY2ss20N9438TMslxV1THgQeBF\ni1TfjHGfzJjjRMclwAPAOr53omPjOX1+nO+djH0ZM3/JGXftoxjrOf0/wNI+GdvPsf3RnmO7Cfhq\nq8eWmf+1P9j1fSZwN/Dicdc+irF2/Z7DzFr1ZeOueRGO7XuAP+22l3cZdeVi1jnRXyVYs9xKIclv\ndq//JfDLwBuT/B/wv8CvVPc3upT0OdZm9Dne64HfSnKGmWO7rdVjW1X3JPkU8BXgO8x8K9vd46t6\nfgb4d/x64B+q6ltjKnUo+hzv24APJLkLCDPLr4t6B08/GStJjZv0NXpJ0gIZ9JLUOINekhpn0EtS\n4wx6SWqcQS9JjTPoJalxBr0kNe7/Afg5YsDtUr8pAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f94389940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_predictions, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f96f6e908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(noise_prediction, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.hstack([test_predictions, noise_prediction])\n",
    "y_pred_dist = np.abs(y_pred - 0.5)\n",
    "y_pred_anomaly = y_pred_dist > 0.2\n",
    "y_test = np.array([[0] * len(test_predictions) + [1] * len(noise_prediction)]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4173354735152488"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_anomaly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see - discriminator prediction distributions for samples from MNIST and noise are very different - so we have relativelly good F1-score.\n",
    "Let's check count of false-positives and false-negatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positives:  237\n"
     ]
    }
   ],
   "source": [
    "print(\"False positives: \", np.logical_and(np.logical_not(y_test), y_pred_anomaly).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False negatives:  126\n"
     ]
    }
   ],
   "source": [
    "print(\"False negatives: \", np.logical_and(y_test, np.logical_not(y_pred_anomaly)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
